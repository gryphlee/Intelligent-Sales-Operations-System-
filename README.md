# Intelligent-Sales-Operations-System-

1. Executive Summary
This document outlines the technical architecture and operational design of the Intelligent Recruitment Automation (IRA) platform. The system is an event-driven data processing pipeline designed to automate the initial stages of the talent acquisition lifecycle, from application ingestion to preliminary candidate screening. By leveraging a stack of modern automation and AI technologies, the IRA platform addresses key business challenges, including high-volume application screening, slow candidate feedback times, and inconsistent initial evaluations. The expected outcome is a significant reduction in manual HR overhead, an accelerated time-to-hire, and the introduction of consistent, data-driven insights into the screening process.

2. Introduction
2.1. Purpose and Scope
The purpose of this document is to provide a comprehensive technical specification for developers, system administrators, and key stakeholders.

In-Scope:

Automated ingestion of candidate applications from a web source.

NLP-driven analysis and scoring of candidate resumes.

Data persistence and deduplication within a structured database.

Automated, multi-tiered email communication with candidates and internal stakeholders.

Out-of-Scope:

Interview scheduling and management.

Candidate onboarding processes.

Long-term performance tracking post-hire.

2.2. Target Audience

System Administrators / DevOps: For deployment, configuration, and maintenance.

Developers / Automation Engineers: For understanding system logic, components, and potential future enhancements.

HR & Operations Managers: For understanding the system's capabilities, logic, and data flow.

2.3. Technology Stack

Orchestration Engine: n8n.io

Data Persistence Layer: Airtable

AI Enrichment Service: OpenAI API (GPT Series)

Notification Service: Gmail API

Ingestion Endpoint: n8n Webhook

3. System Architecture and Design
3.1. High-Level Architecture
The IRA platform is an event-driven, serverless workflow. The architecture is designed around a central orchestration engine (n8n) that integrates with various external SaaS APIs. The system is stateless from the perspective of the orchestrator, with all persistent data stored in the Airtable database.

3.2. Data Processing Pipeline
The workflow executes the following sequence of operations:

Ingestion: A webhook listener ingests a JSON payload from an external form submission.

Validation: A code module validates the payload against a predefined schema. Invalid submissions trigger a terminal notification process.

Data Retrieval: An HTTP client retrieves the resume file (binary) from the provided URL.

AI Enrichment: The resume text is extracted and dispatched to the OpenAI API. The API returns an enriched data object containing a score, summary, and skill analysis.

Data Lookup & Deduplication: The system executes two parallel data retrieval operations against the Airtable API:
a. It resolves the Record ID of the relevant Job Position.
b. It queries the Candidates table by email to detect existing records.

Data Persistence: Based on the deduplication check, the system performs either an UPDATE or a CREATE operation on the Candidates table via the Airtable API, linking the record to the corresponding Job Position.

Communication: The system dispatches emails via the Gmail API based on the outcome of the AI enrichment phase.

4. Data Schema
The persistence layer is composed of two primary tables within a single Airtable Base.

4.1. Table: Candidates
| Field Name | Data Type | Description |
| :--- | :--- | :--- |
| Name | String | Candidate's full name. |
| Email | String (Unique) | Primary key for deduplication. |
| Phone | String | Candidate's phone number. |
| Position | Linked Record | Foreign key link to the Job Positions table. |
| Application Date | Date | Timestamp of the initial application. |
| AI Score | Number | Quantitative score (0-100) from the AI model. |
| Status | String (Single Select)| Current stage in the pipeline (e.g., New, AI Reviewed). |
| AI Summary | String (Long Text) | Qualitative summary generated by the AI model. |

4.2. Table: Job Positions
| Field Name | Data Type | Description |
| :--- | :--- | :--- |
| Position Name | String (Unique) | The primary key for the job role. |
| Department | String | The associated department. |
| Required Skills | String (Long Text) | Key skills required for the role, used for future analysis. |
| Candidates | Linked Record | Links to all candidates who applied for this position. |

5. Implementation & Configuration
5.1. Prerequisites

An active n8n instance.

API access and credentials for Airtable, OpenAI, and Gmail.

A configured Airtable Base adhering to the schema defined in Section 4.

5.2. Credential Management
All API keys and OAuth2 tokens must be configured and stored securely within the n8n credential manager.

5.3. Environment Variables
The following environment variables must be available to the n8n instance:

AIRTABLE_BASE_ID: The unique identifier for the target Airtable Base.

6. Operational Guide
6.1. Execution Trigger
The pipeline is triggered exclusively by a POST request to the configured n8n webhook URL.

6.2. Error Handling
The system has built-in error handling for two primary scenarios:

Invalid Submission: The validation module catches incomplete or malformed data and routes the workflow to a rejection email process.

Node Execution Failure: Failures in API calls (e.g., OpenAI, Airtable) are logged in the n8n execution history and will halt the workflow for that specific run, requiring manual review.

7. Roadmap & Future Enhancements
V1.5 - Advanced NLP: Implement a dedicated PDF-to-text extraction module. Enhance the OpenAI prompt to perform a skill-gap analysis by comparing candidate skills against the Required Skills in the Job Positions table.

V2.0 - BI & Analytics: Integrate the Airtable base with a business intelligence platform (e.g., Looker Studio, Power BI) to create a real-time recruitment analytics dashboard.

V2.5 - ATS Integration: Develop modules to integrate with a dedicated Applicant Tracking System (ATS) for seamless data flow into later stages of the recruitment process.
